{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"y2eZbQUOv2WU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710763215615,"user_tz":-60,"elapsed":2973,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"e7dd86b3-39ff-41ac-a618-6272ea465e42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# gdrive_path='/content/gdrive/MyDrive/Bertopic/shared_work/'\n","\n","# # This will mount your google drive under 'MyDrive'\n","# drive.mount('/content/gdrive', force_remount=True)\n","# # In order to access the files in this notebook we have to navigate to the correct folder\n","\n","\n","# To run from the common drive:\n","dataset_path = '/content/drive/MyDrive/Praktikum - NLP Applications/Datasets/genius_and_wasabi/'\n","drive.mount('/content/gdrive', force_remount=True)\n","# os.chdir(dataset_path)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":874,"status":"ok","timestamp":1710756809196,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"},"user_tz":-60},"id":"SjvTAsN1xeE7","outputId":"63882e9e-96f0-4012-b3b5-58fded0a12e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 5, in <module>\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n","    from pip._internal.build_env import get_runnable_pip\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 15, in <module>\n","    from pip._vendor.packaging.requirements import Requirement\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 10, in <module>\n","    from pip._vendor.pyparsing import (  # noqa\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/__init__.py\", line 140, in <module>\n","    from .core import __diag__, __compat__\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5663, in <module>\n","    _escapedPunc = Word(_bslash, r\"\\[]-*.$+^?()~ \", exact=2).set_parse_action(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 675, in set_parse_action\n","    self.parseAction = [_trim_arity(fn) for fn in fns]\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 675, in <listcomp>\n","    self.parseAction = [_trim_arity(fn) for fn in fns]\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 284, in _trim_arity\n","    _trim_arity_call_line = (_trim_arity_call_line or traceback.extract_stack(limit=2)[-1])\n","  File \"/usr/lib/python3.10/traceback.py\", line 227, in extract_stack\n","    stack = StackSummary.extract(walk_stack(f), limit=limit)\n","  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n","    f.line\n","  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n","    self._line = linecache.getline(self.filename, self.lineno)\n","  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n","    lines = getlines(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 137, in updatecache\n","    lines = fp.readlines()\n","  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n","    def decode(self, input, final=False):\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip install pandas bertopic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10780,"status":"ok","timestamp":1710756819973,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"},"user_tz":-60},"id":"OjxLuNppbUb_","outputId":"5378dfbb-2afe-40d2-d4d2-4f81a9730037"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"]}],"source":["!pip install pandas nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2094,"status":"ok","timestamp":1710756822062,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"},"user_tz":-60},"id":"Y2miiytzbW9m","outputId":"1f5cd29d-70cf-4dc9-d421-84c1813d89fd"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet') # to use wordnet"],"metadata":{"id":"3DFXuRYu1mK_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710756822063,"user_tz":-60,"elapsed":6,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"22d82dbb-11df-4c89-e3c4-4a31ff16c821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from nltk.corpus import wordnet as wn\n","# Find synsets for a word\n","synsets = wn.synsets('dog')\n","print(synsets)"],"metadata":{"id":"w7hrZ6dj1q8h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710756823513,"user_tz":-60,"elapsed":1454,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"8851cdce-ab78-432a-9b02-12feeecf89ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11418,"status":"ok","timestamp":1710756834930,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"},"user_tz":-60},"id":"Hn5o_ANeTuzo","outputId":"096a52c7-ebf3-405a-f4b5-249096ec49b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (69.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n","Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.0.5)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.1.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install --upgrade tensorflow\n"]},{"cell_type":"code","source":["!pip install --force-reinstall tensorflow tensorflow-probability\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IItcB4FAzX4","executionInfo":{"status":"ok","timestamp":1710756907307,"user_tz":-60,"elapsed":72380,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"e8e7f083-7558-4e66-ed20-8ed7a298fbed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow\n","  Using cached tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","Collecting tensorflow-probability\n","  Using cached tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n","Collecting absl-py>=1.0.0 (from tensorflow)\n","  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n","Collecting astunparse>=1.6.0 (from tensorflow)\n","  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting flatbuffers>=23.5.26 (from tensorflow)\n","  Using cached flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n","Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n","  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n","Collecting google-pasta>=0.1.1 (from tensorflow)\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting h5py>=3.10.0 (from tensorflow)\n","  Using cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","Collecting libclang>=13.0.0 (from tensorflow)\n","  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow)\n","  Using cached ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","Collecting opt-einsum>=2.3.2 (from tensorflow)\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting packaging (from tensorflow)\n","  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n","  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","Collecting requests<3,>=2.21.0 (from tensorflow)\n","  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n","Collecting setuptools (from tensorflow)\n","  Using cached setuptools-69.2.0-py3-none-any.whl (821 kB)\n","Collecting six>=1.12.0 (from tensorflow)\n","  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting termcolor>=1.1.0 (from tensorflow)\n","  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n","Collecting typing-extensions>=3.6.6 (from tensorflow)\n","  Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n","Collecting wrapt>=1.11.0 (from tensorflow)\n","  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n","Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n","  Using cached grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n","  Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","Collecting keras>=3.0.0 (from tensorflow)\n","  Using cached keras-3.0.5-py3-none-any.whl (1.0 MB)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n","  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n","Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n","  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","Collecting decorator (from tensorflow-probability)\n","  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","Collecting cloudpickle>=1.3 (from tensorflow-probability)\n","  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n","Collecting dm-tree (from tensorflow-probability)\n","  Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n","  Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n","Collecting rich (from keras>=3.0.0->tensorflow)\n","  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n","Collecting namex (from keras>=3.0.0->tensorflow)\n","  Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n","Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n","  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n","  Using cached idna-3.6-py3-none-any.whl (61 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n","  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n","Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n","  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n","Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n","  Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n","  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n","Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n","  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n","Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow)\n","  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n","  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.0.0->tensorflow)\n","  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n","  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Installing collected packages: namex, libclang, flatbuffers, dm-tree, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, setuptools, pygments, protobuf, packaging, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, gast, decorator, cloudpickle, charset-normalizer, certifi, absl-py, werkzeug, tensorflow-probability, requests, opt-einsum, ml-dtypes, markdown-it-py, h5py, google-pasta, astunparse, tensorboard, rich, keras, tensorflow\n","  Attempting uninstall: namex\n","    Found existing installation: namex 0.0.7\n","    Uninstalling namex-0.0.7:\n","      Successfully uninstalled namex-0.0.7\n","  Attempting uninstall: libclang\n","    Found existing installation: libclang 18.1.1\n","    Uninstalling libclang-18.1.1:\n","      Successfully uninstalled libclang-18.1.1\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 24.3.7\n","    Uninstalling flatbuffers-24.3.7:\n","      Successfully uninstalled flatbuffers-24.3.7\n","  Attempting uninstall: dm-tree\n","    Found existing installation: dm-tree 0.1.8\n","    Uninstalling dm-tree-0.1.8:\n","      Successfully uninstalled dm-tree-0.1.8\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.16.0\n","    Uninstalling wrapt-1.16.0:\n","      Successfully uninstalled wrapt-1.16.0\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.43.0\n","    Uninstalling wheel-0.43.0:\n","      Successfully uninstalled wheel-0.43.0\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.2.1\n","    Uninstalling urllib3-2.2.1:\n","      Successfully uninstalled urllib3-2.2.1\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.10.0\n","    Uninstalling typing_extensions-4.10.0:\n","      Successfully uninstalled typing_extensions-4.10.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.4.0\n","    Uninstalling termcolor-2.4.0:\n","      Successfully uninstalled termcolor-2.4.0\n","  Attempting uninstall: tensorflow-io-gcs-filesystem\n","    Found existing installation: tensorflow-io-gcs-filesystem 0.36.0\n","    Uninstalling tensorflow-io-gcs-filesystem-0.36.0:\n","      Successfully uninstalled tensorflow-io-gcs-filesystem-0.36.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 69.2.0\n","    Uninstalling setuptools-69.2.0:\n","      Successfully uninstalled setuptools-69.2.0\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.17.2\n","    Uninstalling Pygments-2.17.2:\n","      Successfully uninstalled Pygments-2.17.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.3\n","    Uninstalling protobuf-4.25.3:\n","      Successfully uninstalled protobuf-4.25.3\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: mdurl\n","    Found existing installation: mdurl 0.1.2\n","    Uninstalling mdurl-0.1.2:\n","      Successfully uninstalled mdurl-0.1.2\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 2.1.5\n","    Uninstalling MarkupSafe-2.1.5:\n","      Successfully uninstalled MarkupSafe-2.1.5\n","  Attempting uninstall: markdown\n","    Found existing installation: Markdown 3.6\n","    Uninstalling Markdown-3.6:\n","      Successfully uninstalled Markdown-3.6\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.62.1\n","    Uninstalling grpcio-1.62.1:\n","      Successfully uninstalled grpcio-1.62.1\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.4\n","    Uninstalling gast-0.5.4:\n","      Successfully uninstalled gast-0.5.4\n","  Attempting uninstall: decorator\n","    Found existing installation: decorator 5.1.1\n","    Uninstalling decorator-5.1.1:\n","      Successfully uninstalled decorator-5.1.1\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 3.0.0\n","    Uninstalling cloudpickle-3.0.0:\n","      Successfully uninstalled cloudpickle-3.0.0\n","  Attempting uninstall: charset-normalizer\n","    Found existing installation: charset-normalizer 3.3.2\n","    Uninstalling charset-normalizer-3.3.2:\n","      Successfully uninstalled charset-normalizer-3.3.2\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2024.2.2\n","    Uninstalling certifi-2024.2.2:\n","      Successfully uninstalled certifi-2024.2.2\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 2.1.0\n","    Uninstalling absl-py-2.1.0:\n","      Successfully uninstalled absl-py-2.1.0\n","  Attempting uninstall: werkzeug\n","    Found existing installation: Werkzeug 3.0.1\n","    Uninstalling Werkzeug-3.0.1:\n","      Successfully uninstalled Werkzeug-3.0.1\n","  Attempting uninstall: tensorflow-probability\n","    Found existing installation: tensorflow-probability 0.24.0\n","    Uninstalling tensorflow-probability-0.24.0:\n","      Successfully uninstalled tensorflow-probability-0.24.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: opt-einsum\n","    Found existing installation: opt-einsum 3.3.0\n","    Uninstalling opt-einsum-3.3.0:\n","      Successfully uninstalled opt-einsum-3.3.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.3.2\n","    Uninstalling ml-dtypes-0.3.2:\n","      Successfully uninstalled ml-dtypes-0.3.2\n","  Attempting uninstall: markdown-it-py\n","    Found existing installation: markdown-it-py 3.0.0\n","    Uninstalling markdown-it-py-3.0.0:\n","      Successfully uninstalled markdown-it-py-3.0.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.10.0\n","    Uninstalling h5py-3.10.0:\n","      Successfully uninstalled h5py-3.10.0\n","  Attempting uninstall: google-pasta\n","    Found existing installation: google-pasta 0.2.0\n","    Uninstalling google-pasta-0.2.0:\n","      Successfully uninstalled google-pasta-0.2.0\n","  Attempting uninstall: astunparse\n","    Found existing installation: astunparse 1.6.3\n","    Uninstalling astunparse-1.6.3:\n","      Successfully uninstalled astunparse-1.6.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.16.2\n","    Uninstalling tensorboard-2.16.2:\n","      Successfully uninstalled tensorboard-2.16.2\n","  Attempting uninstall: rich\n","    Found existing installation: rich 13.7.1\n","    Uninstalling rich-13.7.1:\n","      Successfully uninstalled rich-13.7.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.0.5\n","    Uninstalling keras-3.0.5:\n","      Successfully uninstalled keras-3.0.5\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.16.1\n","    Uninstalling tensorflow-2.16.1:\n","      Successfully uninstalled tensorflow-2.16.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n","tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.1.0 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.2.2 charset-normalizer-3.3.2 cloudpickle-3.0.0 decorator-5.1.1 dm-tree-0.1.8 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 idna-3.6 keras-3.0.5 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 numpy-1.26.4 opt-einsum-3.3.0 packaging-24.0 protobuf-4.25.3 pygments-2.17.2 requests-2.31.0 rich-13.7.1 setuptools-69.2.0 six-1.16.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 tensorflow-probability-0.24.0 termcolor-2.4.0 typing-extensions-4.10.0 urllib3-2.2.1 werkzeug-3.0.1 wheel-0.43.0 wrapt-1.16.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","certifi","decorator","pkg_resources","setuptools","six"]},"id":"bcf9d7602afb4f279805a6e967eed91f"}},"metadata":{}}]},{"cell_type":"code","source":["!pip show tensorflow bertopic umap-learn\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPSddaaaCk2f","executionInfo":{"status":"ok","timestamp":1710756915138,"user_tz":-60,"elapsed":7836,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"ed5612c9-4e1d-4790-aecd-d8173d33af56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tensorflow\n","Version: 2.16.1\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n","Required-by: dopamine-rl, tf_keras\n","---\n","Name: bertopic\n","Version: 0.16.0\n","Summary: BERTopic performs topic Modeling with state-of-the-art transformer models.\n","Home-page: https://github.com/MaartenGr/BERTopic\n","Author: Maarten P. Grootendorst\n","Author-email: maartengrootendorst@gmail.com\n","License: UNKNOWN\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: hdbscan, numpy, pandas, plotly, scikit-learn, sentence-transformers, tqdm, umap-learn\n","Required-by: \n","---\n","Name: umap-learn\n","Version: 0.5.5\n","Summary: Uniform Manifold Approximation and Projection\n","Home-page: http://github.com/lmcinnes/umap\n","Author: \n","Author-email: \n","License: BSD\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: numba, numpy, pynndescent, scikit-learn, scipy, tqdm\n","Required-by: bertopic\n"]}]},{"cell_type":"code","source":["!pip install --upgrade tensorflow bertopic[all] umap-learn\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUzFm3LHCrZR","executionInfo":{"status":"ok","timestamp":1710756927119,"user_tz":-60,"elapsed":11985,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"0752380f-0ac1-463a-c2e2-d5f9422ca434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: bertopic[all] in /usr/local/lib/python3.10/dist-packages (0.16.0)\n","Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.5)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (69.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n","Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.0.5)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","\u001b[33mWARNING: bertopic 0.16.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic[all]) (0.8.33)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic[all]) (1.5.3)\n","Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic[all]) (1.2.2)\n","Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic[all]) (4.66.2)\n","Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic[all]) (2.5.1)\n","Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic[all]) (5.15.0)\n","Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.4)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.58.1)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.11)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic[all]) (0.29.37)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic[all]) (1.3.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.1.8)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic[all]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic[all]) (2023.4)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic[all]) (8.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic[all]) (3.3.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (4.38.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (9.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic[all]) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic[all]) (2023.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic[all]) (6.0.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.4.99)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic[all]) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic[all]) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic[all]) (0.4.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwVLYZHExIpM","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"error","timestamp":1710756943329,"user_tz":-60,"elapsed":16214,"user":{"displayName":"Danqing Chen","userId":"09845787644688696199"}},"outputId":"6f98b164-2c3a-4b06-f9fe-729195124949"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b31fff1caa58>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mumap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.16.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mumap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msklearn_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparametric_umap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParametricUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     warn(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/parametric_umap.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     warn(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# from tensorflow_probability.google import staging  # DisableOnExport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# from tensorflow_probability.google import tfp_google  # DisableOnExport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;31m# Non-lazy load of packages that register with tensorflow or keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpkg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_maybe_nonlazy_load\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Forces loading the package from its lazy loader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py\u001b[0m in \u001b[0;36m__dir__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py\u001b[0m in \u001b[0;36m_validate_tf_environment\u001b[0;34m(package)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mrequired_tensorflow_version\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mimport\u001b[0m \u001b[0mtf_keras\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0;31m# Print more informative error message, then reraise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtLarge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtSmall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/sequential.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlegacy_sm_saving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/saved_model/load_context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_load_context_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_load_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from bertopic import BERTopic\n","from umap import UMAP\n","\n","# set path of the file\n","csv_file_path = 'concatenated_chunks.csv'\n","df = pd.read_csv(dataset_path + csv_file_path)"]},{"cell_type":"markdown","metadata":{"id":"K4JSLS4VNkmW"},"source":["# **Data Preprocessing**\n","This involves removing the explicit song structure from the lyrics column and initialising the CountVectorizer so that stop word removal is handled internally by BERTopic"]},{"cell_type":"code","source":["df['genre'].value_counts()"],"metadata":{"id":"q2AyERiZa6b7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sampling stratified on genre\n","\n","genre_stratified_df = df.groupby('genre', group_keys=False).apply(lambda x: x.sample(min(len(x), 20000)))\n","genre_stratified_df['genre'].value_counts()"],"metadata":{"id":"0TLm5q4TZszg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = genre_stratified_df"],"metadata":{"id":"JtLNE21GbO8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['gender'].value_counts()"],"metadata":{"id":"VOUBDUVpbc2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-l1RmrFNc6Tz"},"outputs":[],"source":["# Removing explicit song structure as it is not important information\n","import re\n","\n","def remove_explicit_song_structure(lyrics):\n","  pattern = r'\\[.+?\\]'\n","  cleaned_lyrics = re.sub(pattern, '', lyrics)\n","  return cleaned_lyrics\n","\n","df['cleaned_lyrics'] = df['lyrics'].astype(str).apply(remove_explicit_song_structure)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03__9YXSORRq"},"outputs":[],"source":["# Initializing the CountVectorizer with English stop words to pass as a parameter to BERTopic\n","count_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n","# Initialising the UMAP constructor to set the random seed - this is so the results are reproducible\n","\n","umap = UMAP(n_neighbors=15,\n","            n_components=5,\n","            min_dist=0.0,\n","            metric='cosine',\n","            low_memory=False,\n","            random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"SBcNmZJzSTY8"},"source":["# **Create Topics**\n","We select the \"english\" as the main language for our documents. If you want a multilingual model that supports 50+ languages, please select \"multilingual\" instead."]},{"cell_type":"code","source":["# Fitting and saving the BERTopic model - done on the stratified sample\n","model = BERTopic(vectorizer_model=count_vectorizer, language=\"english\", umap_model=umap) #nr_topics=50 parameters find the most similar topics and merge them\n","# model_path = '/content/gdrive/MyDrive/Bertopic/shared_work/mymodel'\n","df['has_lyrics'] = ~df['lyrics'].isna() # flag the rows that have lyrics\n","documents = df[df['has_lyrics']]['cleaned_lyrics'].astype(str).tolist()\n","\n","# Fitting BERTopic\n","topic_model = model.fit(documents)"],"metadata":{"id":"jTJ8XD9ol1NK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model path\n","# model_path = '/content/gdrive/MyDrive/Bertopic/shared_work/mymodel'\n","\n","# Model path for common drive\n","\n","model_path = '/content/drive/MyDrive/Praktikum - NLP Applications/Models/bertopic_' + csv_file_path.split('/')[-1].split('.')[0]\n","\n","stratify = 1\n","if stratify:\n","  model_path += '_stratified'\n","\n","\n","print(model_path)"],"metadata":{"id":"Nk8-M5WqZeiV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving it using safetensors\n","embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n","model.save(model_path, serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)"],"metadata":{"id":"GW3lxrsOwI1f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" If you are loading a pre-trained model, you should use transform() instead of fit_transform() to get the topics for new documents or fit_transform() if you are updating the model with new documents."],"metadata":{"id":"ImyNkqW7oLy-"}},{"cell_type":"markdown","source":["Note: Due to computational limitations, we were unable to run both the fit and transform methods in the same notebook (i.e. we would run out of our daily RAM limit).\n","Therefore, we had to split it into two notebooks - one to train the topic model using the stratified sample and the second to transform it on the entire dataset, in order to make the best use of our computational resources.\n","\n","**Please refer to BERTopic_part2.ipynb for the rest of the topic modelling code.**"],"metadata":{"id":"jlVhVFm0c0rL"}},{"cell_type":"code","source":[],"metadata":{"id":"4R6N8KnHd2A1"},"execution_count":null,"outputs":[]}]}