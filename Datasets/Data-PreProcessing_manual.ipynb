{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":5123,"status":"error","timestamp":1711187747606,"user":{"displayName":"Rasul Khanbayov","userId":"15916312178924372002"},"user_tz":-60},"id":"e9nymqUqZGe0","outputId":"9dc366fb-2865-464a-bd56-cb14b687686e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Bertopic/shared_work/'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c31a9a9b114c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# In order to access the files in this notebook we have to navigate to the correct folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdrive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Check manually if all files are present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Bertopic/shared_work/'"]}],"source":["from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/Bertopic/shared_work/'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","print(sorted(os.listdir()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJtoKtKEs5jH"},"outputs":[],"source":["# importing Songs dataset\n","import pandas as pd\n","\n","dsongs = pd.read_csv('/content/gdrive/MyDrive/Bertopic/Wasabi/wasabi_songs.csv', sep='\\t', low_memory=False)\n","list(dsongs.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SsI5xfWqtPUk"},"outputs":[],"source":["# Selecting only English language songs\n","dsongs_English = dsongs[dsongs['language_detect'] == 'english']\n","\n","# Selecting columns we need for songs dataset, we can add other columns or remove current in the future\n","column_list_for_english_songs = ['artist', 'genre', 'language', 'language_detect', 'title', 'explicit_content_lyrics_predicted']\n","dsongs_English = dsongs_English[column_list_for_english_songs]\n","print(len(dsongs_English))\n","\n","# Saving this file in Datasets folder\n","dsongs_English.to_csv('/content/gdrive/MyDrive/Bertopic/shared_work/wasabi_english_songs.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQsBrhOTlnf6"},"outputs":[],"source":["# Imporint artists dataset\n","import pandas as pd\n","\n","dartists = pd.read_csv('/content/gdrive/MyDrive/Bertopic/Wasabi/wasabi_artists.csv', low_memory=False)\n","list(dartists.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yX0wW-1Pl1br"},"outputs":[],"source":["# Removing entries where Gender is not Male, Female or Other\n","dartists_cleaned = dartists.dropna(subset=['gender'])\n","dartists_cleaned[[\"gender\"]].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGU2l7nqrj1c"},"outputs":[],"source":["# Removing entries where members column in artist is empty []\n","dartists_cleaned_solo = dartists_cleaned[dartists_cleaned['members'] == '[]']\n","\n","# Selecting columns we need for artists dataset, we can add other columns or remove current in the future\n","column_list_for_dartists = ['name', 'gender']\n","dartists_cleaned_solo = dartists_cleaned_solo[column_list_for_dartists]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLLsh_ajyvLa"},"outputs":[],"source":["# Checking new artist dataset where gender and solo artists filtered and chosen\n","dartists_cleaned_solo[[\"gender\"]].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZ90CR3QuIEU"},"outputs":[],"source":["# Choosing artist name from songs dataset with english language and removing the other ones\n","# (the ones that does not sing in english, because in artist it is not specified fully in what language artist sings, we went forward from Songs to Artists)\n","idxs = list(dsongs_English.artist.values)\n","\n","dartists_cleaned_solo = dartists_cleaned_solo[pd.Series(list(dartists_cleaned_solo.name), index=dartists_cleaned_solo.index).isin(idxs)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpI6Pq1my3gU"},"outputs":[],"source":["# Checking new artist dataset where english singing artists are kept\n","dartists_cleaned_solo[[\"gender\"]].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1H3og4K3y-Ru"},"outputs":[],"source":["# Saving the file for artists datasrt\n","dartists_cleaned_solo.to_csv('/content/gdrive/MyDrive/Bertopic/shared_work/wasabi_artist_new_dartists.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z657HHWCr7cP"},"outputs":[],"source":["df_male = dartists_cleaned_solo[dartists_cleaned_solo['gender'] == 'Male']\n","df_female = dartists_cleaned_solo[dartists_cleaned_solo['gender'] == 'Female']\n","\n","# Determine the smaller size among the two groups\n","min_size = min(len(df_male), len(df_female))\n","\n","# Truncate both datasets to have the same size\n","df_male_balanced = df_male.sample(min_size)\n","df_female_balanced = df_female.sample(min_size)\n","\n","# Combine the balanced datasets\n","df_balanced = pd.concat([df_male_balanced, df_female_balanced])\n","df_balanced.to_csv('/content/gdrive/MyDrive/Bertopic/shared_work/wasabi_new_dartists_balanced.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1d9TXdtCzWE3"},"outputs":[],"source":["df_balanced[[\"gender\"]].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wp35NBJT00qI"},"outputs":[],"source":["print(len(dsongs_English))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VzAiNiB0zoQ"},"outputs":[],"source":["# Again removing songs which does not belong to artists in wasabi_new_dartists_balanced.csv file\n","idxs2 = list(df_balanced.name.values)\n","\n","dsongs2_English = dsongs_English[pd.Series(list(dsongs_English.artist), index=dsongs_English.index).isin(idxs2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IH3scVg1eFT"},"outputs":[],"source":["print(len(dsongs2_English))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_y1oeKg18DO"},"outputs":[],"source":["dsongs2_English.to_csv('/content/gdrive/MyDrive/Bertopic/shared_work/wasabi_new_songs_english_balanced_artists.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Bq23Owd2XCx"},"outputs":[],"source":["import requests\n","\n","class MusixMatch:\n","    def __init__(self, api_key):\n","        self.api_key = api_key\n","        self.base_url = \"http://api.musixmatch.com/ws/1.1/\"\n","\n","    def _make_request(self, method, params):\n","        params['apikey'] = self.api_key\n","        response = requests.get(self.base_url + method, params=params)\n","        response.raise_for_status()\n","        return response.json()\n","\n","    def search_track(self, track_name):\n","        method = 'track.search'\n","        params = {'q_track': track_name, 'page_size': 1, 'page': 1, 's_track_rating': 'desc'}\n","        data = self._make_request(method, params)\n","        track_list = data['message']['body']['track_list']\n","        return track_list[0]['track']['track_id'] if track_list else None\n","\n","    def get_lyrics(self, track_id):\n","        method = 'track.lyrics.get'\n","        params = {'track_id': track_id}\n","        data = self._make_request(method, params)\n","        return data['message']['body']['lyrics']['lyrics_body'] if data['message']['body'] else None\n","\n","api_key = 'da10a106601943f9899e0695231a139d\t\t'\n","musixmatch = MusixMatch(api_key)\n","\n","# Search for a track and get its lyrics\n","track_name = \"Shape of You\"\n","track_id = musixmatch.search_track(track_name)\n","if track_id:\n","    lyrics = musixmatch.get_lyrics(track_id)\n","    print(\"Lyrics:\\n\", lyrics)\n","else:\n","    print(\"Track not found.\")\n","\n","# get the lyrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzFmimBX2mqK"},"outputs":[],"source":["import pandas as pd\n","\n","def append_lyrics_to_csv(csv_file_path, api_key, start_row=0):\n","    musixmatch = MusixMatch(api_key)\n","    df = pd.read_csv(csv_file_path)\n","\n","    # Add a 'lyrics_addbyus' column if it doesn't exist\n","    if 'lyrics_addbyus' not in df.columns:\n","        df['lyrics_addbyus'] = pd.NA\n","\n","    for i, row in df.iterrows():\n","        if i < start_row:\n","            continue  # Skip rows until the starting row is reached\n","\n","        # Check if lyrics are already present\n","        if pd.isna(df.at[i, 'lyrics_addbyus']):\n","            print(i)\n","            track_name = row['title']  # Replace 'title' with your actual column name if different\n","            track_id = musixmatch.search_track(track_name)\n","            if track_id:\n","                lyrics = musixmatch.get_lyrics(track_id)\n","                df.at[i, 'lyrics_addbyus'] = lyrics  # Add lyrics to the DataFrame\n","            else:\n","                df.at[i, 'lyrics_addbyus'] = \"Lyrics Not Found\"\n","\n","            # Save progress after each update directly to the same CSV file\n","            df.to_csv(csv_file_path, index=False)\n","\n","# Example usage\n","csv_file_path = '/content/drive/MyDrive/Praktikum - NLP Applications/Datasets/wasabi_new_songs_english_balanced_artists.csv'\n","api_key = 'da10a106601943f9899e0695231a139d'  # Your Musixmatch API key\n","start_row = 8276  # Set the row number from which you want to start fetching lyrics, change it everytime you ran the code\n","append_lyrics_to_csv(csv_file_path, api_key, start_row)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}