{"cells":[{"cell_type":"code","execution_count":null,"id":"fb74233f","metadata":{"id":"fb74233f"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import pandas as pd\n","import json as js\n","import os\n","from textwrap import wrap\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","#from matplotlib.ticker import MaxNLocator"]},{"cell_type":"code","execution_count":null,"id":"cedbdeff","metadata":{"id":"cedbdeff"},"outputs":[],"source":["# creating/checking folder structure\n","paths = [\"./dictionaries\", \"./embeddings\",\"./results\", \"./tables\", \"./plots\"]\n","for path in paths:\n","    if not os.path.isdir(path):\n","        os.mkdir(path)\n",""]},{"cell_type":"markdown","id":"49d7a0bb","metadata":{"id":"49d7a0bb"},"source":["### Loading results"]},{"cell_type":"code","execution_count":null,"id":"b8be5606","metadata":{"id":"b8be5606"},"outputs":[],"source":["# loading the model specifications\n","with open(\"models.json\", \"r\") as f:\n","    models = js.load(f)\n","\n","# loading the gendered terms and names\n","\n","with open(\"./dictionaries/gendered_terms_and_names.json\", \"r\") as f:\n","    population_dict = js.load(f)\n","\n","# loading stereotype dimensions\n","with open(\"./stereotype_dimensions.txt\", \"r\") as f:\n","    stereotype_dimensions = [dimension[:-1] for dimension in f.readlines()]\n","\n","stereotype_dictionary = pd.read_csv(\"./dictionaries/stereotype_dictionary_generated_examples.csv\", index_col = 0)\n","additional_terms = pd.read_csv(\"./dictionaries/additional_terms_generated_examples.csv\", index_col = 0)"]},{"cell_type":"code","execution_count":null,"id":"9c419ec2","metadata":{"id":"9c419ec2"},"outputs":[],"source":["# loading the polar projections\n","\n","stereotype_results = pd.read_csv(\"./results/stereotype_results_with_stats.csv\", index_col = 0)\n","\n","stereotype_results_additional_terms = pd.read_csv(\"./results/stereotype_results_additional_terms.csv\", index_col = 0)\n","\n","antonym_results = pd.read_csv(\"./results/antonym_results_with_stats.csv\", index_col = 0)\n","\n","stereotype_results.head()"]},{"cell_type":"code","execution_count":null,"id":"44cc11b9","metadata":{"id":"44cc11b9"},"outputs":[],"source":["# loading the results from the validy experiment\n","\n","accuracy_df = pd.read_csv(\"./results/additional_terms_accuracy.csv\", index_col = 0)\n","\n","# table for accuracy by term idx\n","term_idx_df = pd.read_csv(\"./results/additional_terms_accuracy_by_term_idx.csv\", index_col = 0)\n","gen_term_idx_df = pd.read_csv(\"./results/additional_terms_accuracy_by_gen_term_idx.csv\", index_col = 0)"]},{"cell_type":"code","execution_count":null,"id":"d395dc20","metadata":{"id":"d395dc20"},"outputs":[],"source":["# setting line and marker styles for the plots\n","\n","styles = {\"line\":\n","          {\"Female Terms\": \"solid\",\n","            \"Female Names\": \"solid\",\n","            \"Male Terms\": \"dashdot\",\n","            \"Male Names\": \"dashdot\"},\n","          \"marker\":\n","          {\"Female Terms\": \"o\",\n","            \"Female Names\": \"d\",\n","            \"Male Terms\": \"o\",\n","            \"Male Names\": \"d\"},\n","          \"color\":\n","          {\"Female Terms\": \"forestgreen\",\n","            \"Female Names\": \"forestgreen\",\n","            \"Male Terms\": \"darkslateblue\",\n","            \"Male Names\": \"darkslateblue\"}\n","\n","         }\n","\n","\n","# setting the models for which to generate additional plots\n","selection = [\"BERT-NoContext-L0\",\n","             \"BERT-DictExamples-L12\",\n","             \"BERT-GenExamples-L12\",\n","            \"BERT-SensePolar\"]"]},{"cell_type":"markdown","id":"545d77e7-54ca-46fb-ade3-947e69a806e0","metadata":{"id":"545d77e7-54ca-46fb-ade3-947e69a806e0"},"source":["# Properties of Generated Examples"]},{"cell_type":"code","execution_count":null,"id":"abfb7253-2e4d-40bb-b5c6-92a252b31e1e","metadata":{"id":"abfb7253-2e4d-40bb-b5c6-92a252b31e1e"},"outputs":[],"source":["# plotting\n","fig, ax1 = plt.subplots(2, 2)\n","\n","ax1[0, 0].hist(stereotype_dictionary[\"avg_example_length\"])\n","ax1[0, 0].set_title(\"\\n\".join(wrap('n words - dictionary examples', 20)), fontweight=\"bold\", size=20)\n","\n","ax1[0,1].hist(stereotype_dictionary[\"average_example_term_idx\"])\n","ax1[0, 1].set_title(\"\\n\".join(wrap('term position - dictionary examples', 20)), fontweight=\"bold\", size=20)\n","\n","ax1[1,0].hist(stereotype_dictionary[\"avg_gen_example_length\"])\n","ax1[1, 0].set_title(\"\\n\".join(wrap('n words - generated examples', 20)), fontweight=\"bold\", size=20)\n","\n","ax1[1,1].hist(stereotype_dictionary[\"avg_gen_example_term_idx\"])\n","ax1[1, 1].set_title(\"\\n\".join(wrap('term position - generated examples', 20)), fontweight=\"bold\", size=20)\n","\n","# adjust ax limits\n","for col in [0,1]:\n","\n","    x_min = min(ax1[0, col].get_xlim()[0], ax1[1,col].get_xlim()[0])\n","    x_max = max(ax1[0, col].get_xlim()[1], ax1[1,col].get_xlim()[1])\n","    y_min = min(ax1[0, col].get_ylim()[0], ax1[1,col].get_ylim()[0])\n","    y_max = max(ax1[0, col].get_ylim()[1], ax1[1,col].get_ylim()[1])\n","\n","    for row in [0,1]:\n","        ax1[row,col].set_xlim(x_min, x_max)\n","        ax1[row,col].set_ylim(y_min, y_max)\n","        ax1[row,col].set_xticks(range(0, int(x_max),5))\n","        ax1[row,col].set_xticklabels(range(0, int(x_max),5),fontsize = 17)\n","        ax1[row,col].set_yticks(range(0, int(y_max),40))\n","        ax1[row,col].set_yticklabels(range(0, int(y_max),40),fontsize = 17)\n","\n","\n","\n","fig.set_figwidth(10)\n","fig.set_figheight(8)\n","\n","fig.tight_layout()\n","plt.savefig(f'./plots/example_properties_for_dictionary_terms.pdf')"]},{"cell_type":"code","execution_count":null,"id":"6e55e4c9-3599-46fc-bf01-0ebe53008e1a","metadata":{"id":"6e55e4c9-3599-46fc-bf01-0ebe53008e1a"},"outputs":[],"source":["# plotting\n","fig, ax1 = plt.subplots(2, 2)\n","\n","# not counting examples twice for overlapping dimensions\n","additional_terms_ = additional_terms.loc[additional_terms[\"dimension\"].isin(stereotype_dimensions)]\n","\n","ax1[0, 0].hist(additional_terms_[\"avg_example_length\"])\n","ax1[0, 0].set_title(\"\\n\".join(wrap('n words - dictionary examples', 20)), fontweight=\"bold\", size=20)\n","ax1[0, 0].set_xlabel(\"n words\")\n","\n","ax1[0,1].hist(additional_terms_[\"average_example_term_idx\"])\n","ax1[0, 1].set_title(\"\\n\".join(wrap('term position - dictionary examples', 20)), fontweight=\"bold\", size=20)\n","\n","ax1[1,0].hist(additional_terms_[\"avg_gen_example_length\"])\n","ax1[1, 0].set_title(\"\\n\".join(wrap('n words - generated examples', 20)), fontweight=\"bold\", size=20)\n","\n","ax1[1,1].hist(additional_terms_[\"avg_gen_example_term_idx\"])\n","ax1[1, 1].set_title(\"\\n\".join(wrap('term position - generated examples', 20)), fontweight=\"bold\", size=20)\n","\n","# adjust ax limits\n","for col in [0,1]:\n","\n","    x_min = min(ax1[0, col].get_xlim()[0], ax1[1,col].get_xlim()[0])\n","    x_max = max(ax1[0, col].get_xlim()[1], ax1[1,col].get_xlim()[1])\n","    y_min = min(ax1[0, col].get_ylim()[0], ax1[1,col].get_ylim()[0])\n","    y_max = max(ax1[0, col].get_ylim()[1], ax1[1,col].get_ylim()[1])\n","\n","    for row in [0,1]:\n","        ax1[row,col].set_xlim(x_min, x_max)\n","        ax1[row,col].set_ylim(y_min, y_max)\n","        ax1[row,col].set_xticks(range(0, int(x_max),5))\n","        ax1[row,col].set_xticklabels(range(0, int(x_max),5),fontsize = 17)\n","        ax1[row,col].set_yticks(range(0, int(y_max),200))\n","        ax1[row,col].set_yticklabels(range(0, int(y_max),200),fontsize = 17)\n","\n","\n","\n","fig.set_figwidth(10)\n","fig.set_figheight(8)\n","\n","fig.tight_layout()\n","plt.savefig(f'./plots/example_properties_for_additional_terms.pdf')"]},{"cell_type":"markdown","id":"09f0847d","metadata":{"id":"09f0847d"},"source":["# Stereotype Dimensions across BERT Layers"]},{"cell_type":"code","execution_count":null,"id":"91d91eb4-af60-42ba-8e67-639e70e286a6","metadata":{"id":"91d91eb4-af60-42ba-8e67-639e70e286a6"},"outputs":[],"source":["#overall accuracy plot\n","\n","xticks = [i for i in range(13)]\n","\n","for tokens in [\"one_token_only\", \"all\"]:\n","\n","    selected_rows = accuracy_df.loc[accuracy_df[\"Tokens\"] == tokens]\n","\n","    fig, ax1 = plt.subplots(5)\n","    row = 0\n","\n","    for model_group in ['BERT','AlBERT','GPT2','GPTNeo','Bloom']:\n","\n","        layers = [i for i in range(0, 25, 2)] if model_group == \"Bloom\" else xticks\n","\n","        model_rows = selected_rows.loc[selected_rows[\"Model\"].str.startswith(model_group)]\n","\n","        ax1[row].plot(xticks,model_rows.loc[model_rows[\"Model\"].str.contains(\"DictExamples\"),\"Overall Accuracy\"], label = \"DictExamples\", color =\"teal\", linestyle = \"solid\")\n","        ax1[row].plot(xticks,model_rows.loc[model_rows[\"Model\"].str.contains(\"GenExamples\"), \"Overall Accuracy\"],label = \"GenExamples\", color = \"blue\", linestyle = \"dotted\")\n","        ax1[row].plot(xticks,model_rows.loc[model_rows[\"Model\"].str.contains(\"NoContext\"), \"Overall Accuracy\"], label = \"NoContext\",color = \"indigo\", linestyle = \"dashdot\")\n","\n","        ax1[row].set_title(model_group, size=15,style='italic')\n","        ax1[row].set_xticks(xticks)\n","        ax1[row].set_xticklabels(layers, size=12)\n","        ax1[row].set_ylim([0.35,0.85])\n","        ax1[row].set_yticks([0.4,0.5, 0.6, 0.7, 0.8])\n","        ax1[row].set_yticklabels([0.4,0.5, 0.6, 0.7, 0.8], size=12)\n","        row+=1\n","\n","    ax1[0].legend(fontsize = 12)\n","    ax1[2].set_ylabel(\"Accuracy\", size=15)\n","    ax1[4].set_xlabel(\"Layers\", size=15)\n","\n","    fig.set_figwidth(6)\n","    fig.set_figheight(10)\n","    fig.tight_layout()\n","\n","    plt.savefig(f'./plots/stereotype_dimensions_across_layers_{tokens}.pdf')\n","\n"]},{"cell_type":"markdown","id":"df1aa6df-109a-40a5-8378-ea9bc782d285","metadata":{"id":"df1aa6df-109a-40a5-8378-ea9bc782d285"},"source":["## Accuracy for individual dimensions"]},{"cell_type":"code","execution_count":null,"id":"c3f85c92-84b6-4a00-9480-efb4a7a15c56","metadata":{"id":"c3f85c92-84b6-4a00-9480-efb4a7a15c56"},"outputs":[],"source":["\n","xticks = [i for i in range(13)]\n","\n","\n","\n","selected_rows = accuracy_df.loc[accuracy_df[\"Tokens\"] == \"all\"]\n","\n","fig, ax1 = plt.subplots(5)\n","row = 0\n","\n","for model_group in ['BERT-GenExamples','AlBERT-GenExamples','GPT2-GenExamples','GPTNeo-GenExamples','Bloom-GenExamples']:\n","\n","    layers = [i for i in range(0, 25, 2)] if model_group == \"Bloom-GenExamples\" else xticks\n","\n","    model_rows = selected_rows.loc[selected_rows[\"Model\"].str.startswith(model_group)]\n","\n","\n","    for dimension in stereotype_dimensions:\n","\n","        ax1[row].plot(xticks,model_rows[dimension], label = dimension)\n","\n","    ax1[row].set_title(model_group, size=15, style='italic')\n","    ax1[row].set_xticks(xticks)\n","    ax1[row].set_xticklabels(layers, size=12)\n","    ax1[row].set_ylim([0.3,1])\n","    ax1[row].set_yticks([0.4, 0.6,  0.8,1])\n","    ax1[row].set_yticklabels([0.4, 0.6,  0.8,1], size=12)\n","    row+=1\n","\n","ax1[0].legend(loc = \"lower left\", fontsize = 10)\n","ax1[2].set_ylabel(\"Accuracy\", size=15)\n","ax1[4].set_xlabel(\"Layers\", size=15)\n","\n","fig.set_figwidth(6)\n","fig.set_figheight(10)\n","fig.tight_layout()\n","\n","plt.savefig(f'./plots/individual_stereotype_dimensions_across_layers.pdf')\n"]},{"cell_type":"markdown","id":"3a0fe3ae-8599-49c9-8bda-d61e87c4218e","metadata":{"id":"3a0fe3ae-8599-49c9-8bda-d61e87c4218e"},"source":["## Accuracy for Warmth and Competence"]},{"cell_type":"code","execution_count":null,"id":"77dae707-5776-4db3-8bde-932cdf64c157","metadata":{"id":"77dae707-5776-4db3-8bde-932cdf64c157"},"outputs":[],"source":["xticks = [i for i in range(13)]\n","\n","selected_rows = accuracy_df.loc[accuracy_df[\"Tokens\"] == \"all\"]\n","\n","fig, ax1 = plt.subplots(1,2)\n","\n","\n","col = 0\n","\n","for dimension in [\"Warmth\", \"Competence\"]:\n","\n","    for model_group in ['BERT-GenExamples','AlBERT-GenExamples','GPT2-GenExamples','GPTNeo-GenExamples','Bloom-GenExamples']:\n","\n","        model_rows = selected_rows.loc[selected_rows[\"Model\"].str.startswith(model_group)]\n","\n","        ax1[col].plot(xticks,model_rows[dimension], label = model_group , linestyle = \"solid\" )\n","\n","\n","        layers = [i for i in range(0, 25, 2)] if model_group == \"Bloom-GenExamples\" else xticks\n","\n","    ax1[col].set_title(dimension, size=15,style='italic')\n","    ax1[col].set_xticks(xticks)\n","    ax1[col].set_xticklabels(xticks, size=12)\n","    ax1[col].set_ylim([0.3,0.85])\n","    #ax1[row].set_yticks([0.4, 0.6,  0.8,1])\n","    #ax1[row].set_yticklabels([0.4, 0.6,  0.8,1], size=12)\n","    col+=1\n","\n","ax1[0].legend(loc = \"lower left\", fontsize = 10)\n","ax1[0].set_ylabel(\"Accuracy\", size=15)\n","ax1[0].set_xlabel(\"Layers$^\\ddagger$\", size=15)\n","ax1[1].set_xlabel(\"Layers$^\\ddagger$\", size=15)\n","\n","fig.set_figwidth(12)\n","fig.set_figheight(4)\n","fig.tight_layout()\n","\n","plt.savefig(f'./plots/warmth_competence_across_layers.pdf')\n"]},{"cell_type":"markdown","id":"2d5ec766-cf70-4b8a-b74c-20d8d737c1e7","metadata":{"id":"2d5ec766-cf70-4b8a-b74c-20d8d737c1e7"},"source":["### Accuracy by Term Position"]},{"cell_type":"code","execution_count":null,"id":"1cd99b3b-faa2-433e-ba06-969c3b99fa5f","metadata":{"id":"1cd99b3b-faa2-433e-ba06-969c3b99fa5f"},"outputs":[],"source":["# accuracy by term_idx plot\n","\n","xticks = [i for i in range(7)]\n","\n","fig, ax1 = plt.subplots(1,1)\n","\n","\n","\n","for model in ['BERT-GenExamples','AlBERT-GenExamples','GPT2-GenExamples','GPTNeo-GenExamples','Bloom-GenExamples']:\n","\n","    model_row = gen_term_idx_df.loc[gen_term_idx_df[\"Model\"]== model, [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7+\"]]\n","\n","    ax1.plot(xticks,model_row.values[0], label = model , linestyle = \"solid\" )\n","\n","\n","        #layers = [i for i in range(0, 25, 2)] if model_group == \"Bloom-GenExamples\" else xticks\n","\n","    #ax1.set_title(dimension, size=15,style='italic')\n","    ax1.set_xticks(xticks)\n","    ax1.set_xticklabels([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7+\"], size=12)\n","    ax1.set_ylim([0.25,0.9])\n","    #ax1[row].set_yticks([0.4, 0.6,  0.8,1])\n","    #ax1[row].set_yticklabels([0.4, 0.6,  0.8,1], size=12)\n","\n","ax1.legend(loc = \"lower left\", fontsize = 10)\n","ax1.set_ylabel(\"Accuracy\", size=15)\n","ax1.set_xlabel(\"Term Position\", size=15)\n","ax1.set_xlabel(\"Term Position\", size=15)\n","\n","fig.set_figwidth(8)\n","fig.set_figheight(4)\n","fig.tight_layout()\n","\n","plt.savefig(f'./plots/accuracy_by_term_position_generated_examples.pdf')"]},{"cell_type":"code","execution_count":null,"id":"104616c6","metadata":{"id":"104616c6"},"outputs":[],"source":["#warmth, competence accuracy by term_idx plot\n","\n","xticks = [i for i in range(7)]\n","\n","fig, ax1 = plt.subplots(1,1)\n","\n","\n","\n","for model in ['BERT-DictExamples','AlBERT-DictExamples','GPT2-DictExamples','GPTNeo-DictExamples','Bloom-DictExamples']:\n","\n","    model_row = term_idx_df.loc[term_idx_df[\"Model\"]== model, [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7+\"]]\n","\n","    ax1.plot(xticks,model_row.values[0], label = model , linestyle = \"solid\" )\n","\n","\n","        #layers = [i for i in range(0, 25, 2)] if model_group == \"Bloom-GenExamples\" else xticks\n","\n","    #ax1.set_title(dimension, size=15,style='italic')\n","    ax1.set_xticks(xticks)\n","    ax1.set_xticklabels([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7+\"], size=12)\n","    ax1.set_ylim([0.25,0.9])\n","    #ax1[row].set_yticks([0.4, 0.6,  0.8,1])\n","    #ax1[row].set_yticklabels([0.4, 0.6,  0.8,1], size=12)\n","\n","ax1.legend(loc = \"lower left\", fontsize = 10)\n","ax1.set_ylabel(\"Accuracy\", size=15)\n","ax1.set_xlabel(\"Term Position\", size=15)\n","ax1.set_xlabel(\"Term Position\", size=15)\n","\n","fig.set_figwidth(8)\n","fig.set_figheight(4)\n","fig.tight_layout()\n","\n","plt.savefig(f'./plots/accuracy_by_term_position_dictionary_examples.pdf')"]},{"cell_type":"markdown","id":"565bc2cd","metadata":{"id":"565bc2cd"},"source":["## Bias Profile of Stereotype Dimensions"]},{"cell_type":"code","execution_count":null,"id":"8351d5b0-f410-4c64-9563-6050fab21a25","metadata":{"id":"8351d5b0-f410-4c64-9563-6050fab21a25"},"outputs":[],"source":["# selection and order of stereotype dimensions\n","plot_dimensions = [\"Religion\",\n","                   \"Politics\", \"Status\",\n","    \"Agency\", \"Ability\", \"Competence\", \"Morality\", \"Sociability\", \"Warmth\"]\n","\n","\n","# polar labels following the definition of the dimension by Nicolas\n","polar_labels = {\"Warmth\": {\"low\": \"low WARMTH\",\n","                          \"high\": \"high WARMTH\"},\n","                \"Competence\": {\"low\": \"low COMPETENCE\",\n","                          \"high\": \"high COMPETENCE\"},\n","    \"Sociability\": {\"low\": \"low sociability\",\n","                          \"high\": \"high sociability\"},\n","          \"Morality\": {\"low\": \"low morality\",\n","                          \"high\": \"high morality\"},\n","          \"Ability\": {\"low\": \"low ability\",\n","                     \"high\": \"high ability\"},\n","         \"Agency\": {\"low\": \"low agency\",\n","                     \"high\": \"high agency\"},\n","        \"Status\": {\"low\": \"low status\",\n","                     \"high\": \"high status\"},\n","        \"Politics\": {\"low\": \"progressive\",\n","                     \"high\": \"traditional\"},\n","        \"Religion\": {\"low\": \"non-religious\",\n","                     \"high\": \"religious\"}\n","         }\n","\n","\n","\n","# looping over models\n","for model_group in ['BERT-GenExamples','AlBERT-GenExamples','GPT2-GenExamples','GPTNeo-GenExamples','Bloom-GenExamples']:\n","\n","    layers = [i for i in range(0, 25, 2)] if model_group == \"Bloom-GenExamples\" else [i for i in range(13)]\n","\n","    subplot_name1 = \"Terms and Names Average Across Layers\"\n","    subplot_name2 = \"Stereotype Profile\"\n","\n","\n","    cm = plt.get_cmap('viridis')\n","    cNorm  = colors.Normalize(vmin=layers[0], vmax=layers[-1])\n","    scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cm)\n","\n","    # dictionary to collect the semantic differential labels\n","    plot_labels = {subplot_name1:{\n","                \"low labels\": [],\n","                 \"high labels\": []},\n","                   subplot_name2:{\n","                \"low labels\": [],\n","                 \"high labels\": []}\n","                  }\n","\n","\n","    # dictionary to collect the values to plot\n","    plot_values = {subplot_name1: {layer:[] for layer in layers},\n","                   subplot_name2: {\"Female Terms\": [],\n","                            \"Female Names\": [],\n","                            \"Male Terms\": [],\n","                            \"Male Names\": []}\n","                  }\n","\n","\n","    # filling the dictionaries\n","    for dimension in plot_dimensions:\n","\n","        for layer in layers:\n","\n","            row = stereotype_results.loc[(stereotype_results[\"Model\"] == model_group + \"-L\" + str(layer)) & (stereotype_results[\"Dimension\"] == dimension)]\n","\n","            #plot_values[\"Female Terms\"][layer].append(row[\"female_terms_mean\"])\n","            mean = (row[\"female_terms_mean\"]+row[\"male_terms_mean\"]+row[\"female_names_mean\"]+ row[\"male_names_mean\"])/4\n","            plot_values[subplot_name1][layer].append(mean)\n","            #plot_values[\"Female Names\"].append(row[\"female_names_mean\"])\n","            #plot_values[\"Female Bias\"][layer].append(row[\"female_terms_mean\"]-mean)\n","            #plot_values[\"Male Bias\"][layer].append(row[\"male_terms_mean\"]-mean)\n","            #plot_values[\"Male Names\"].append(row[\"male_names_mean\"])\n","\n","        row = stereotype_results.loc[(stereotype_results[\"Model\"] == model_group) & (stereotype_results[\"Dimension\"] == dimension)]\n","\n","        mean = (row[\"female_terms_mean\"]+row[\"male_terms_mean\"]+row[\"female_names_mean\"]+ row[\"male_names_mean\"])/4\n","\n","        plot_values[subplot_name2][\"Female Terms\"].append((row[\"female_terms_mean\"]-mean))\n","        plot_values[subplot_name2][\"Female Names\"].append((row[\"female_names_mean\"]-mean))\n","        plot_values[subplot_name2][\"Male Terms\"].append((row[\"male_terms_mean\"]-mean))\n","        plot_values[subplot_name2][\"Male Names\"].append((row[\"male_names_mean\"]-mean))\n","\n","        # set polar labels, with significance\n","        low_label = polar_labels[dimension][\"low\"]\n","        high_label = polar_labels[dimension][\"high\"]\n","\n","        plot_labels[subplot_name1][\"low labels\"].append(low_label)\n","        plot_labels[subplot_name1][\"high labels\"].append(high_label)\n","\n","        if row[\"gendered_terms_diff_pvalue\"].values[0] <0.05:\n","            high_label = high_label + \"$^*$\"\n","\n","        if row[\"names_diff_pvalue\"].values[0] < 0.05:\n","             high_label = high_label + \"$^\\ddagger$\"\n","\n","        plot_labels[subplot_name2][\"low labels\"].append(low_label)\n","        plot_labels[subplot_name2][\"high labels\"].append(high_label)\n","\n","\n","    # plotting\n","    fig, ax1 = plt.subplots(1, 2)\n","    col = 0\n","\n","    for subplot, lines in plot_values.items():\n","\n","\n","        #if words == \"All Terms\":\n","        for line, values in lines.items():\n","            if subplot == subplot_name1:\n","                color = scalarMap.to_rgba(line)\n","                marker = None\n","            else:\n","                color = styles[\"color\"][line]\n","                marker = styles[\"marker\"][line]\n","            ax1[col].plot(values, np.arange(len(values)), label = str(line), color = color, marker = marker)#,  color = styles[\"color\"][words], linestyle = styles[\"line\"][words])\n","\n","        # centering the plot\n","        max_abs_value = abs(max([j for i in [j for i in plot_values[subplot].values() for j in i] for j in i],key=abs))\n","        ax1[col].set_xlim(-max_abs_value-0.1*max_abs_value, max_abs_value+0.1*max_abs_value)\n","\n","        #ax1[col].hlines(y=6.5, xmin=-max_abs_value-0.5*max_abs_value, xmax=max_abs_value+0.5*max_abs_value, linewidth=1, linestyle = \"dotted\",color='black')\n","\n","        # setting left side tick labels\n","        ax1_tick_labels = plot_labels[subplot][\"low labels\"]\n","        ax1[col].set_yticks(np.arange(len(ax1_tick_labels)))\n","        ax1[col].set_yticklabels(ax1_tick_labels)\n","        #ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # depending on the range of values\n","\n","        # setting right side tick labels\n","        ax2_tick_labels = plot_labels[subplot][\"high labels\"]\n","        ax2 = ax1[col].twinx()\n","        ax2.set_ylim(ax1[col].get_ylim())\n","        ax2.set_yticks(np.arange(len(ax2_tick_labels)))\n","        ax2.set_yticklabels(ax2_tick_labels)\n","\n","\n","\n","    # possibly at line at x =0\n","\n","        ax1[col].legend(loc=\"lower left\")\n","        ax1[col].set_title(subplot)\n","\n","        col+=1\n","\n","    fig.suptitle(model_group)\n","    fig.set_figwidth(12)\n","    fig.set_figheight(4)\n","    fig.tight_layout()\n","    plt.savefig(f'./plots/stereotype_profile_{model_group}.pdf')\n","\n"]},{"cell_type":"markdown","id":"1af5fe15-d539-42c8-b38e-423364114fb8","metadata":{"id":"1af5fe15-d539-42c8-b38e-423364114fb8"},"source":["### last layers"]},{"cell_type":"code","execution_count":null,"id":"a5883da6","metadata":{"id":"a5883da6"},"outputs":[],"source":["# selection and order of stereotype dimensions\n","plot_dimensions = [\"Religion\",\n","                   \"Politics\", \"Status\",\n","    \"Agency\", \"Ability\", \"Competence\", \"Morality\", \"Sociability\", \"Warmth\"]\n","\n","\n","# polar labels following the definition of the dimension by Nicolas\n","polar_labels = {\"Warmth\": {\"low\": \"low WARMTH\",\n","                          \"high\": \"high WARMTH\"},\n","                \"Competence\": {\"low\": \"low COMPETENCE\",\n","                          \"high\": \"high COMPETENCE\"},\n","    \"Sociability\": {\"low\": \"low sociability\",\n","                          \"high\": \"high sociability\"},\n","          \"Morality\": {\"low\": \"low morality\",\n","                          \"high\": \"high morality\"},\n","          \"Ability\": {\"low\": \"low ability\",\n","                     \"high\": \"high ability\"},\n","         \"Agency\": {\"low\": \"low agency\",\n","                     \"high\": \"high agency\"},\n","        \"Status\": {\"low\": \"low status\",\n","                     \"high\": \"high status\"},\n","        \"Politics\": {\"low\": \"progressive\",\n","                     \"high\": \"traditional\"},\n","        \"Religion\": {\"low\": \"non-religious\",\n","                     \"high\": \"religious\"}\n","         }\n","\n","\n","\n","# looping over models\n","for model in ['BERT-GenExamples-L12','AlBERT-GenExamples-L12','GPT2-GenExamples-L12','GPTNeo-GenExamples-L12','Bloom-GenExamples-L12']:\n","\n","    # dictionary to collect the semantic differential labels\n","    plot_labels = {\"low labels\": [],\n","                 \"high labels\": []}\n","\n","    # dictionary to collect the values to plot\n","    plot_values = {\"Female Terms\": [],\n","                \"Female Names\": [],\n","                \"Male Terms\": [],\n","            \"Male Names\": []\n","                  }\n","\n","    # filling the dictionaries\n","    for dimension in plot_dimensions:\n","\n","        row = stereotype_results.loc[(stereotype_results[\"Model\"] == model) & (stereotype_results[\"Dimension\"] == dimension)]\n","\n","        if len(row)== 1:\n","\n","            plot_values[\"Female Terms\"].append(row[\"female_terms_mean\"])\n","            plot_values[\"Female Names\"].append(row[\"female_names_mean\"])\n","            plot_values[\"Male Terms\"].append(row[\"male_terms_mean\"])\n","            plot_values[\"Male Names\"].append(row[\"male_names_mean\"])\n","\n","\n","            # set polar labels, with significance\n","            low_label = polar_labels[dimension][\"low\"]\n","            high_label = polar_labels[dimension][\"high\"]\n","\n","            if row[\"gendered_terms_diff_pvalue\"].values[0] <0.05:\n","                high_label = high_label + \"$^*$\"\n","\n","            if row[\"names_diff_pvalue\"].values[0] < 0.05:\n","                high_label = high_label + \"$^\\ddagger$\"\n","\n","            plot_labels[\"low labels\"].append(low_label)\n","            plot_labels[\"high labels\"].append(high_label)\n","\n","\n","    # plotting\n","    fig, ax1 = plt.subplots(1, 1)\n","\n","    for words, values in plot_values.items():\n","        ax1.plot(values, np.arange(len(values)), label = words, marker = styles[\"marker\"][words],  color = styles[\"color\"][words], linestyle = styles[\"line\"][words])\n","\n","    # centering the plot\n","    max_abs_value = abs(max([j for i in [j for i in plot_values.values() for j in i] for j in i],key=abs))\n","    ax1.set_xlim(-max_abs_value-0.1*max_abs_value, max_abs_value+0.1*max_abs_value)\n","\n","\n","    # setting left side tick labels\n","    ax1_tick_labels = plot_labels[\"low labels\"]\n","    ax1.set_yticks(np.arange(len(ax1_tick_labels)))\n","    ax1.set_yticklabels(ax1_tick_labels)\n","    #ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # depending on the range of values\n","\n","    # setting right side tick labels\n","    ax2_tick_labels = plot_labels[\"high labels\"]\n","    ax2 = ax1.twinx()\n","    ax2.set_ylim(ax1.get_ylim())\n","    ax2.set_yticks(np.arange(len(ax2_tick_labels)))\n","    ax2.set_yticklabels(ax2_tick_labels)\n","\n","    # possibly at line at x =0\n","\n","    ax1.legend(loc=\"lower left\")\n","    ax1.set_title(model)\n","\n","    fig.set_figwidth(6)\n","    fig.set_figheight(4)\n","    fig.tight_layout()\n","    plt.savefig(f'./plots/stereotype_profile_{model}.pdf')\n","\n"]},{"cell_type":"markdown","id":"d91fb641","metadata":{"id":"d91fb641"},"source":["### Top 10 Most Biased Antonym Pairs"]},{"cell_type":"code","execution_count":null,"id":"3f77a720","metadata":{"id":"3f77a720"},"outputs":[],"source":["\n","# selecting the criteria for sorting the antonym pairs\n","criteria = \"gendered_terms_diff_abs\"\n","\n","\n","# looping over models\n","for model in [\"BERT-DictExamples-L12\"]:\n","\n","    # filtering the dataframe\n","    plot_df = antonym_results.loc[(antonym_results[\"Model\"] == model) ].sort_values(criteria, ascending = False).head(10)\n","\n","\n","    # dictionary to collect the semantic differential labels\n","    plot_labels = {\"low labels\": [],\n","                 \"high labels\": []}\n","\n","    # dictionary to collect the values to plot\n","    plot_values = {\"Female Terms\": [],\n","                \"Female Names\": [],\n","                \"Male Terms\": [],\n","                \"Male Names\": []}\n","\n","    # filling the dictionaries\n","    for index, row in plot_df.iloc[::-1].iterrows():\n","\n","        plot_values[\"Female Terms\"].append(row[\"female_terms_mean\"])\n","        plot_values[\"Female Names\"].append(row[\"female_names_mean\"])\n","        plot_values[\"Male Terms\"].append(row[\"male_terms_mean\"])\n","        plot_values[\"Male Names\"].append(row[\"male_names_mean\"])\n","\n","\n","        # set polar labels, with significance\n","        low_label = row[\"term1\"]\n","        high_label = row[\"term2\"]\n","\n","        if row[\"gendered_terms_diff_pvalue\"] <0.05:\n","            high_label = high_label + \"$^*$\"\n","\n","        if row[\"names_diff_pvalue\"] < 0.05:\n","            high_label = high_label + \"$^\\ddagger$\"\n","\n","        plot_labels[\"low labels\"].append(low_label)\n","        plot_labels[\"high labels\"].append(high_label)\n","\n","\n","\n","\n","    # plotting\n","    fig, ax1 = plt.subplots(1, 1)\n","\n","    for words, values in plot_values.items():\n","        ax1.plot(values, np.arange(len(values)), label = words, marker = styles[\"marker\"][words],  color = styles[\"color\"][words], linestyle = styles[\"line\"][words])\n","\n","\n","    # centering the plot\n","    max_abs_value = abs(max([j for i in plot_values.values() for j in i],key=abs))\n","    ax1.set_xlim(-max_abs_value-0.1*max_abs_value, max_abs_value+0.1*max_abs_value)\n","\n","    # setting left side tick labels\n","    ax1_tick_labels = plot_labels[\"low labels\"]\n","    ax1.set_yticks(np.arange(len(ax1_tick_labels)))\n","    ax1.set_yticklabels(ax1_tick_labels)\n","    #ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # depending on the range of values\n","\n","    # setting right side tick labels\n","    ax2_tick_labels = plot_labels[\"high labels\"]\n","    ax2 = ax1.twinx()\n","    ax2.set_ylim(ax1.get_ylim())\n","    ax2.set_yticks(np.arange(len(ax2_tick_labels)))\n","    ax2.set_yticklabels(ax2_tick_labels)\n","\n","    ax1.legend()\n","\n","\n","    fig.tight_layout()\n","    plt.savefig(f'./plots/top10_biased_antonym_pairs_{model}.pdf')"]},{"cell_type":"markdown","id":"bb4d9c92","metadata":{"id":"bb4d9c92"},"source":["# Cover Plot Handpicked Example"]},{"cell_type":"code","execution_count":null,"id":"53db7350-343d-41b3-ae6d-5ec59c2b82fd","metadata":{"id":"53db7350-343d-41b3-ae6d-5ec59c2b82fd"},"outputs":[],"source":["label_dict = {\"female_names_mean\": \"Female Names\",\n","             \"female_terms_mean\": \"Female Terms\",\n","              \"male_names_mean\": \"Male Names\",\n","             \"male_terms_mean\": \"Male Terms\"\n","             }\n","\n","\n","for model_group in ['BERT-GenExamples','AlBERT-GenExamples','GPT2-GenExamples','GPTNeo-GenExamples','Bloom-GenExamples']:\n","\n","    model_rows = stereotype_results.loc[stereotype_results[\"Model\"] == model_group]\n","\n","    warmth = model_rows.loc[model_rows[\"Dimension\"] == \"Warmth\"]\n","    competence = model_rows.loc[model_rows[\"Dimension\"] == \"Competence\"]\n","\n","    fig, ax1 = plt.subplots(1, 1)\n","\n","\n","    female_population = [\"female_terms_mean\", \"female_names_mean\"]\n","    male_population = [\"male_terms_mean\", \"male_names_mean\"]\n","    population = female_population + male_population\n","\n","    marker = {word:\"s\" for word in female_population}\n","    marker.update({word:\"d\" for word in male_population})\n","\n","    color = {word: \"forestgreen\" for word in female_population}\n","    color.update({word: \"darkslateblue\" for word in male_population})\n","\n","    xlim1 = min([warmth[term].values[0] for term in population])\n","    xlim2 = max([warmth[term].values[0] for term in population])\n","    ax1.set_xlim(xlim1-0.1*(abs(xlim2-xlim1)), xlim2+0.35*(xlim2-xlim1))\n","\n","    ylim1 = min([competence[term].values[0] for term in population])\n","    ylim2 = max([competence[term].values[0] for term in population])\n","    ax1.set_ylim(ylim1-0.2*(abs(ylim2-ylim1)), ylim2+0.1*(ylim2-ylim1))\n","\n","    ax1.set_xlabel(\"Warmth\", size=15)\n","    ax1.set_ylabel(\"Competence\", size=15)\n","\n","    ax1.set_title(model_group, fontstyle = \"italic\", size=15)\n","\n","\n","    for word in population:\n","\n","        x  = warmth[word].values[0]\n","        y = competence[word].values[0]\n","\n","        ax1.plot(x, y, marker[word], label = word, color = color[word])\n","\n","        if word in [\"female_names_mean\", \"female_terms_mean\"]:\n","\n","            ax1.text(x+0.02*abs((xlim2-xlim1)),y, label_dict[word],size=15)\n","        else:\n","            ax1.text(x+0.02*abs((xlim2-xlim1)),y-0.125*abs((ylim2-ylim1)), label_dict[word],size=15)\n","\n","\n","    fig.set_figwidth(6)\n","    fig.set_figheight(2.5)\n","    fig.tight_layout()\n","    plt.savefig(f'./plots/cover_plot_{model_group}.pdf')\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"87a09783-b016-4f6c-bc95-0b26593e2701","metadata":{"id":"87a09783-b016-4f6c-bc95-0b26593e2701"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}